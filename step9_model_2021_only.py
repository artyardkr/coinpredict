import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("Phase 3: ëª¨ë¸ í›ˆë ¨ (2021ë…„ ë°ì´í„°ë§Œ, 7:3 ë¶„í• )")
print("=" * 70)

# ===== 1. ë°ì´í„° ë¡œë“œ =====
print("\n1. ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§")
print("-" * 70)

df = pd.read_csv('integrated_data_full.csv', index_col=0, parse_dates=True)
print(f"ì „ì²´ ë°ì´í„°: {df.shape} ({df.index[0].date()} ~ {df.index[-1].date()})")

# 2021ë…„ ë°ì´í„°ë§Œ í•„í„°ë§
df_2021 = df[df.index.year == 2021].copy()
print(f"2021ë…„ ë°ì´í„°: {df_2021.shape} ({df_2021.index[0].date()} ~ {df_2021.index[-1].date()})")

# íƒ€ê²Ÿ ì„¤ì •
df_2021['target'] = df_2021['Close'].shift(-1)
df_2021 = df_2021.dropna(subset=['target'])

print(f"íƒ€ê²Ÿ ìƒì„± í›„: {df_2021.shape}")

# ì œê±°í•  íŠ¹ì„±
exclude_cols = ['Close', 'target', 'cumulative_return', 'High', 'Low', 'Open',
                'bc_market_price', 'bc_market_cap']
all_features = [col for col in df_2021.columns if col not in exclude_cols]

X = df_2021[all_features].copy()
y = df_2021['target'].copy()

print(f"íŠ¹ì„±: {len(all_features)}ê°œ")
print(f"ìƒ˜í”Œ: {len(X)}ê°œ")

# ===== 2. 7:3 ë¶„í•  =====
print("\n2. 7:3 ë°ì´í„° ë¶„í• ")
print("-" * 70)

split_idx = int(len(X) * 0.7)

X_train = X.iloc[:split_idx]
X_test = X.iloc[split_idx:]
y_train = y.iloc[:split_idx]
y_test = y.iloc[split_idx:]

print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ ({X_train.index[0].date()} ~ {X_train.index[-1].date()})")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ ({X_test.index[0].date()} ~ {X_test.index[-1].date()})")

# ===== 3. íŠ¹ì„± ì§‘í•© ë¡œë“œ =====
print("\n3. íŠ¹ì„± ì§‘í•© ë¡œë“œ")
print("-" * 70)

feature_sets = {}

for n in [10, 20, 30, 40, 50]:
    with open(f'selected_features_top{n}.txt', 'r') as f:
        lines = f.readlines()
        features = [line.strip().split('. ')[1] for line in lines if line.strip() and '. ' in line]
        feature_sets[f'top{n}'] = features
        print(f"âœ“ Top {n}: {len(features)}ê°œ")

feature_sets['all'] = all_features
print(f"âœ“ All: {len(all_features)}ê°œ")

# ===== 4. ëª¨ë¸ í›ˆë ¨ í•¨ìˆ˜ =====
def train_and_evaluate(X_train, X_test, y_train, y_test, model_name, model):
    """ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"""

    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # í›ˆë ¨
    model.fit(X_train_scaled, y_train)

    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    # í‰ê°€
    results = {
        'model': model_name,
        'train_r2': r2_score(y_train, y_train_pred),
        'test_r2': r2_score(y_test, y_test_pred),
        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),
        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),
        'train_mae': mean_absolute_error(y_train, y_train_pred),
        'test_mae': mean_absolute_error(y_test, y_test_pred),
        'train_mape': np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100,
        'test_mape': np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100,
    }

    return results, model, y_test_pred, scaler

# ===== 5. ëª¨ë¸ë³„, íŠ¹ì„± ì§‘í•©ë³„ í›ˆë ¨ =====
print("\n" + "=" * 70)
print("4. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ (2021ë…„ ë°ì´í„°)")
print("=" * 70)

all_results = []
predictions = {}

for feature_name, features in feature_sets.items():
    print(f"\n{'='*70}")
    print(f"íŠ¹ì„± ì§‘í•©: {feature_name} ({len(features)}ê°œ)")
    print(f"{'='*70}")

    # í•´ë‹¹ íŠ¹ì„±ë§Œ ì„ íƒ
    X_subset = X[features].copy()
    X_train_subset = X_train[features].copy()
    X_test_subset = X_test[features].copy()

    # ===== Random Forest =====
    print(f"\n[Random Forest]")
    rf = RandomForestRegressor(
        n_estimators=100,
        max_depth=5,
        min_samples_split=20,
        min_samples_leaf=10,
        random_state=42,
        n_jobs=-1
    )

    rf_results, rf_model, rf_pred, rf_scaler = train_and_evaluate(
        X_train_subset, X_test_subset, y_train, y_test,
        f'RF_{feature_name}', rf
    )
    rf_results['feature_set'] = feature_name
    rf_results['n_features'] = len(features)
    all_results.append(rf_results)
    predictions[f'RF_{feature_name}'] = rf_pred

    print(f"  Train RÂ²: {rf_results['train_r2']:.4f} | Test RÂ²: {rf_results['test_r2']:.4f}")
    print(f"  Train RMSE: ${rf_results['train_rmse']:,.2f} | Test RMSE: ${rf_results['test_rmse']:,.2f}")
    print(f"  Train MAE: ${rf_results['train_mae']:,.2f} | Test MAE: ${rf_results['test_mae']:,.2f}")
    print(f"  Train MAPE: {rf_results['train_mape']:.2f}% | Test MAPE: {rf_results['test_mape']:.2f}%")

    # ===== XGBoost =====
    print(f"\n[XGBoost]")
    xgb_model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=3,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )

    xgb_results, xgb_fitted, xgb_pred, xgb_scaler = train_and_evaluate(
        X_train_subset, X_test_subset, y_train, y_test,
        f'XGB_{feature_name}', xgb_model
    )
    xgb_results['feature_set'] = feature_name
    xgb_results['n_features'] = len(features)
    all_results.append(xgb_results)
    predictions[f'XGB_{feature_name}'] = xgb_pred

    print(f"  Train RÂ²: {xgb_results['train_r2']:.4f} | Test RÂ²: {xgb_results['test_r2']:.4f}")
    print(f"  Train RMSE: ${xgb_results['train_rmse']:,.2f} | Test RMSE: ${xgb_results['test_rmse']:,.2f}")
    print(f"  Train MAE: ${xgb_results['train_mae']:,.2f} | Test MAE: ${xgb_results['test_mae']:,.2f}")
    print(f"  Train MAPE: {xgb_results['train_mape']:.2f}% | Test MAPE: {xgb_results['test_mape']:.2f}%")

# ===== 6. ê²°ê³¼ ì €ì¥ =====
print("\n" + "=" * 70)
print("5. ê²°ê³¼ ì €ì¥")
print("=" * 70)

results_df = pd.DataFrame(all_results)
results_df = results_df.sort_values('test_r2', ascending=False)

results_df.to_csv('model_results_2021.csv', index=False)
print("âœ“ model_results_2021.csv")

print("\nìµœê³  ì„±ëŠ¥ ëª¨ë¸ (Test RÂ² ê¸°ì¤€):")
print("-" * 70)
for i, row in results_df.head(5).iterrows():
    print(f"{i+1}. {row['model']:20} | RÂ²: {row['test_r2']:7.4f} | RMSE: ${row['test_rmse']:8,.2f} | MAPE: {row['test_mape']:5.2f}% | {int(row['n_features'])}ê°œ")

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸
best_model = results_df.iloc[0]
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_model['model']}")
print(f"   Test RÂ²: {best_model['test_r2']:.4f}")
print(f"   Test RMSE: ${best_model['test_rmse']:,.2f}")
print(f"   Test MAPE: {best_model['test_mape']:.2f}%")

# ===== 7. ì‹œê°í™” =====
print("\n6. ê²°ê³¼ ì‹œê°í™”")
print("-" * 70)

fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# 1. íŠ¹ì„± ìˆ˜ vs RÂ²
for model_type in ['RF', 'XGB']:
    model_results = results_df[results_df['model'].str.contains(model_type)]
    axes[0, 0].plot(model_results['n_features'], model_results['train_r2'],
                    marker='o', label=f'{model_type} Train', alpha=0.7)
    axes[0, 0].plot(model_results['n_features'], model_results['test_r2'],
                    marker='s', label=f'{model_type} Test', linewidth=2)

axes[0, 0].set_xlabel('Number of Features', fontsize=11)
axes[0, 0].set_ylabel('RÂ² Score', fontsize=11)
axes[0, 0].set_title('RÂ² Score vs Number of Features (2021 Data)', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)

# 2. íŠ¹ì„± ìˆ˜ vs RMSE
for model_type in ['RF', 'XGB']:
    model_results = results_df[results_df['model'].str.contains(model_type)]
    axes[0, 1].plot(model_results['n_features'], model_results['test_rmse'],
                    marker='s', label=f'{model_type} Test', linewidth=2)

axes[0, 1].set_xlabel('Number of Features', fontsize=11)
axes[0, 1].set_ylabel('RMSE ($)', fontsize=11)
axes[0, 1].set_title('Test RMSE vs Number of Features', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. íŠ¹ì„± ìˆ˜ vs MAPE
for model_type in ['RF', 'XGB']:
    model_results = results_df[results_df['model'].str.contains(model_type)]
    axes[0, 2].plot(model_results['n_features'], model_results['test_mape'],
                    marker='s', label=f'{model_type} Test', linewidth=2)

axes[0, 2].set_xlabel('Number of Features', fontsize=11)
axes[0, 2].set_ylabel('MAPE (%)', fontsize=11)
axes[0, 2].set_title('Test MAPE vs Number of Features', fontsize=12, fontweight='bold')
axes[0, 2].legend()
axes[0, 2].grid(True, alpha=0.3)

# 4. Train vs Test RÂ² (ê³¼ì í•© ì²´í¬)
axes[1, 0].scatter(results_df['train_r2'], results_df['test_r2'],
                   c=results_df['n_features'], cmap='viridis', s=100, alpha=0.6)
axes[1, 0].plot([0, 1], [0, 1], 'r--', label='Perfect Fit', linewidth=2)
axes[1, 0].set_xlabel('Train RÂ²', fontsize=11)
axes[1, 0].set_ylabel('Test RÂ²', fontsize=11)
axes[1, 0].set_title('Train vs Test RÂ² (Overfitting Check)', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)
cbar = plt.colorbar(axes[1, 0].collections[0], ax=axes[1, 0])
cbar.set_label('# Features')

# 5. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
best_pred = predictions[best_model['model']]
axes[1, 1].scatter(y_test, best_pred, alpha=0.5, s=30)
axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
                'r--', linewidth=2, label='Perfect Prediction')
axes[1, 1].set_xlabel('Actual Price ($)', fontsize=11)
axes[1, 1].set_ylabel('Predicted Price ($)', fontsize=11)
axes[1, 1].set_title(f'Actual vs Predicted ({best_model["model"]})', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

# 6. ì‹œê³„ì—´ ì˜ˆì¸¡ í”Œë¡¯ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
test_dates = y_test.index
axes[1, 2].plot(test_dates, y_test.values, label='Actual', linewidth=2, color='blue')
axes[1, 2].plot(test_dates, best_pred, label='Predicted', linewidth=2,
                color='red', alpha=0.7, linestyle='--')
axes[1, 2].set_xlabel('Date', fontsize=11)
axes[1, 2].set_ylabel('BTC Price ($)', fontsize=11)
axes[1, 2].set_title(f'Time Series Prediction ({best_model["model"]})', fontsize=12, fontweight='bold')
axes[1, 2].legend()
axes[1, 2].grid(True, alpha=0.3)
axes[1, 2].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.savefig('model_performance_2021.png', dpi=300, bbox_inches='tight')
print("âœ“ model_performance_2021.png")

plt.close()

# ===== 8. ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼ =====
print("\n7. ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)")
print("-" * 70)

# ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„
errors = y_test - best_pred
abs_errors = np.abs(errors)
pct_errors = (errors / y_test) * 100

print(f"\nì˜ˆì¸¡ ì˜¤ì°¨ í†µê³„:")
print(f"  í‰ê·  ì˜¤ì°¨: ${errors.mean():,.2f}")
print(f"  í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): ${abs_errors.mean():,.2f}")
print(f"  í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ (MAPE): {np.abs(pct_errors).mean():.2f}%")
print(f"  ìµœëŒ€ ì˜¤ì°¨: ${abs_errors.max():,.2f}")
print(f"  ìµœì†Œ ì˜¤ì°¨: ${abs_errors.min():,.2f}")

# ì˜ˆì¸¡ ì •í™•ë„ ë¶„í¬
within_1pct = (np.abs(pct_errors) < 1).sum() / len(pct_errors) * 100
within_2pct = (np.abs(pct_errors) < 2).sum() / len(pct_errors) * 100
within_5pct = (np.abs(pct_errors) < 5).sum() / len(pct_errors) * 100

print(f"\nì˜ˆì¸¡ ì •í™•ë„ ë¶„í¬:")
print(f"  Â±1% ì´ë‚´: {within_1pct:.1f}%")
print(f"  Â±2% ì´ë‚´: {within_2pct:.1f}%")
print(f"  Â±5% ì´ë‚´: {within_5pct:.1f}%")

print("\n" + "=" * 70)
print("2021ë…„ ë°ì´í„° ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
print("=" * 70)
