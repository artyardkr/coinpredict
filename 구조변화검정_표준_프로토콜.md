# êµ¬ì¡°ë³€í™” ê²€ì • í‘œì¤€ í”„ë¡œí† ì½œ (Structural Change Testing Protocol)

**Bitcoin ETF Impact Analysis - Standardized Testing Framework**

**ì‘ì„±ì¼**: 2025-11-09
**ë²„ì „**: 1.0
**ëª©ì **: ì¬í˜„ ê°€ëŠ¥í•˜ê³  ì²´ê³„ì ì¸ êµ¬ì¡°ë³€í™” ê²€ì • í”„ë¡œì„¸ìŠ¤ ì •ë¦½

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [3ë‹¨ê³„ ê²€ì • í”„ë¡œí† ì½œ](#2-3ë‹¨ê³„-ê²€ì •-í”„ë¡œí† ì½œ)
3. [ë°ì´í„° ì¤€ë¹„ (í‘œì¤€í™”)](#3-ë°ì´í„°-ì¤€ë¹„-í‘œì¤€í™”)
4. [ê²€ì • 1: Chow Test](#4-ê²€ì •-1-chow-test)
5. [ê²€ì • 2: Quandt-Andrews Test](#5-ê²€ì •-2-quandt-andrews-test)
6. [ê²€ì • 3: CUSUM Test](#6-ê²€ì •-3-cusum-test)
7. [ê²°ê³¼ í•´ì„ ê¸°ì¤€](#7-ê²°ê³¼-í•´ì„-ê¸°ì¤€)
8. [í‘œì¤€ ë³´ê³  ì–‘ì‹](#8-í‘œì¤€-ë³´ê³ -ì–‘ì‹)
9. [ì²´í¬ë¦¬ìŠ¤íŠ¸](#9-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## 1. ê°œìš”

### 1.1 ëª©ì 

êµ¬ì¡°ë³€í™” ê²€ì •ì˜ **ì¬í˜„ ê°€ëŠ¥ì„±**, **ì¼ê´€ì„±**, **ì‹ ë¢°ì„±**ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ í‘œì¤€í™”ëœ í”„ë¡œí† ì½œ

### 1.2 ì ìš© ëŒ€ìƒ

- ì‹œê³„ì—´ ë°ì´í„°ì˜ êµ¬ì¡°ë³€í™” ê²€ì •
- íŠ¹ì • ì´ë²¤íŠ¸(ì˜ˆ: ETF ìŠ¹ì¸)ì˜ ì˜í–¥ ë¶„ì„
- ì—¬ëŸ¬ ë³€ìˆ˜ì˜ ì¼ê´€ëœ ê²€ì •

### 1.3 í•µì‹¬ ì›ì¹™

1. **í‘œì¤€í™”**: ëª¨ë“  ë³€ìˆ˜ì— ë™ì¼í•œ ê¸°ì¤€ ì ìš©
2. **ë‹¤ê°ë„ ê²€ì¦**: 3ê°€ì§€ ë…ë¦½ì  ê²€ì •ìœ¼ë¡œ êµì°¨ í™•ì¸
3. **í†µê³„ì  ì—„ê²©ì„±**: ë‹¤ì¤‘ ê²€ì • ë³´ì •, HAC í‘œì¤€ì˜¤ì°¨ ì ìš©
4. **ì¬í˜„ ê°€ëŠ¥ì„±**: ëª¨ë“  ë‹¨ê³„ ë¬¸ì„œí™” ë° ì½”ë“œ ê³µê°œ

---

## 2. 3ë‹¨ê³„ ê²€ì • í”„ë¡œí† ì½œ

### 2.1 ê²€ì • ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  êµ¬ì¡°ë³€í™” ê²€ì • íŒŒì´í”„ë¼ì¸                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë‹¨ê³„ 0: ë°ì´í„° í‘œì¤€í™”
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1           â”‚
â”‚ Chow Test        â”‚  ëª©ì : íŠ¹ì • ë‚ ì§œ(ETF ìŠ¹ì¸ì¼)ì— êµ¬ì¡°ë³€í™” í™•ì¸
â”‚ (Known Break)    â”‚  ì…ë ¥: ë³€í™”ì  ë‚ ì§œ ì§€ì •
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  ì¶œë ¥: F-í†µê³„ëŸ‰, p-value
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2           â”‚
â”‚ Quandt-Andrews   â”‚  ëª©ì : ë°ì´í„°ì—ì„œ ë³€í™”ì  ì°¾ê¸°
â”‚ (Unknown Break)  â”‚  ì…ë ¥: íƒìƒ‰ êµ¬ê°„ (15%-85%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  ì¶œë ¥: sup F-í†µê³„ëŸ‰, ë³€í™”ì  ë‚ ì§œ
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3           â”‚
â”‚ CUSUM Test       â”‚  ëª©ì : ì ì§„ì  vs ê¸‰ê²©í•œ ë³€í™” êµ¬ë¶„
â”‚ (Change Type)    â”‚  ì…ë ¥: ëˆ„ì í•© ê²½ê³„ì„ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  ì¶œë ¥: ê²½ê³„ ì´íƒˆ ì—¬ë¶€, ë³€í™” ì†ë„
   â†“
ê²°ê³¼ í†µí•© ë° í•´ì„
```

### 2.2 ê²€ì • ê°„ ê´€ê³„

| ê²€ì • | ë³€í™”ì  | ëª©ì  | ìƒí˜¸ë³´ì™„ |
|------|--------|------|---------|
| **Chow** | ì•Œë ¤ì§„ ë‚ ì§œ | "ETF ë‚ ì§œì— ì •ë§ ë³€í–ˆë‚˜?" | QAì™€ ë‚ ì§œ ë¹„êµ |
| **Quandt-Andrews** | ë°ì´í„°ì—ì„œ íƒìƒ‰ | "ì§„ì§œ ë³€í™”ì ì´ ì–¸ì œ?" | Chow ê²°ê³¼ ê²€ì¦ |
| **CUSUM** | ë³€í™” ìœ í˜• | "ì–´ë–»ê²Œ ë³€í–ˆë‚˜?" | ë³€í™” ì†ë„ íŒŒì•… |

---

## 3. ë°ì´í„° ì¤€ë¹„ (í‘œì¤€í™”)

### 3.1 í•„ìˆ˜ ì „ì²˜ë¦¬

#### Step 0.1: ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
# í‘œì¤€ ë°©ë²•: Forward Fill â†’ Backward Fill â†’ Median
df = df.fillna(method='ffill').fillna(method='bfill').fillna(df.median())

# ê²€ì¦
assert df.isnull().sum().sum() == 0, "ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ìˆìŒ!"
```

#### Step 0.2: ì´ìƒì¹˜ ì²˜ë¦¬ (Winsorization)

```python
from scipy.stats.mstats import winsorize

# ìƒí•˜ìœ„ 1% ì ˆì‚¬ (í‘œì¤€)
for col in df.select_dtypes(include=[np.number]).columns:
    df[col] = winsorize(df[col], limits=[0.01, 0.01])
```

**ì´ìœ **: ë¹„íŠ¸ì½”ì¸ì˜ ê·¹ì‹¬í•œ ë³€ë™ì„±(ì¼ì¼ Â±30%) ì˜í–¥ ìµœì†Œí™”

#### Step 0.3: ë³€ìˆ˜ í‘œì¤€í™” (Z-Score)

```python
from sklearn.preprocessing import StandardScaler

# ê° ë³€ìˆ˜ë¥¼ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ í‘œì¤€í™”
scaler = StandardScaler()
df_scaled = pd.DataFrame(
    scaler.fit_transform(df),
    columns=df.columns,
    index=df.index
)
```

**ì¥ì **:
- âœ… ë³€ìˆ˜ ê°„ ìŠ¤ì¼€ì¼ ì°¨ì´ ì œê±° (DFF: 0-5 vs bc_hash_rate: ìˆ˜ì–µ)
- âœ… F-í†µê³„ëŸ‰ ë¹„êµ ê°€ëŠ¥
- âœ… ê³„ìˆ˜ í•´ì„ ì¼ê´€ì„±

#### Step 0.4: ë³€í™”ì  ë‚ ì§œ ì„¤ì •

```python
# í‘œì¤€ ì„¤ì •
BREAKPOINT_DATE = '2024-01-10'  # ETF ìŠ¹ì¸ì¼
TRIM_PERCENT = 0.15  # QA Test íƒìƒ‰ êµ¬ê°„ (15%-85%)
```

---

## 4. ê²€ì • 1: Chow Test

### 4.1 ëª©ì 

**"ETF ìŠ¹ì¸ì¼(2024-01-10)ì„ ê¸°ì¤€ìœ¼ë¡œ íšŒê·€ê³„ìˆ˜ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ë³€í–ˆëŠ”ê°€?"**

### 4.2 ê°€ì„¤

```
Hâ‚€ (ê·€ë¬´ê°€ì„¤): Î²â‚ = Î²â‚‚ (ETF ì „í›„ ê³„ìˆ˜ ë™ì¼, êµ¬ì¡°ë³€í™” ì—†ìŒ)
Hâ‚ (ëŒ€ë¦½ê°€ì„¤): Î²â‚ â‰  Î²â‚‚ (ETF ì „í›„ ê³„ìˆ˜ ë‹¤ë¦„, êµ¬ì¡°ë³€í™” ìˆìŒ)
```

### 4.3 í‘œì¤€ í”„ë¡œì„¸ìŠ¤

#### Step 1.1: ë°ì´í„° ë¶„í• 

```python
# í‘œì¤€ ë¶„í• ì 
breakpoint_date = pd.to_datetime('2024-01-10')
breakpoint_idx = df.index.get_loc(breakpoint_date)

# ë¶„í• 
df_pre = df.iloc[:breakpoint_idx]    # ETF ì´ì „
df_post = df.iloc[breakpoint_idx:]   # ETF ì´í›„

print(f"ETF ì´ì „: {len(df_pre)}ì¼ ({df_pre.index[0]} ~ {df_pre.index[-1]})")
print(f"ETF ì´í›„: {len(df_post)}ì¼ ({df_post.index[0]} ~ {df_post.index[-1]})")
```

#### Step 1.2: ë‹¨ë³€ëŸ‰ íšŒê·€ (í•µì‹¬!)

```python
import statsmodels.api as sm

def chow_test_standardized(y, X, breakpoint_idx):
    """
    í‘œì¤€í™”ëœ Chow Test

    Parameters:
    -----------
    y : pd.Series (í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜)
    X : pd.DataFrame (í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜, constant í¬í•¨)
    breakpoint_idx : int (ë³€í™”ì  ì¸ë±ìŠ¤)

    Returns:
    --------
    dict: F-í†µê³„ëŸ‰, p-value, ê³„ìˆ˜ ë³€í™”
    """

    # 1. ì „ì²´ íšŒê·€
    model_full = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': 5})
    rss_full = model_full.ssr

    # 2. ë¶„í•  íšŒê·€
    X1, y1 = X[:breakpoint_idx], y[:breakpoint_idx]
    X2, y2 = X[breakpoint_idx:], y[breakpoint_idx:]

    model1 = sm.OLS(y1, X1).fit(cov_type='HAC', cov_kwds={'maxlags': 5})
    model2 = sm.OLS(y2, X2).fit(cov_type='HAC', cov_kwds={'maxlags': 5})

    rss1 = model1.ssr
    rss2 = model2.ssr

    # 3. Chow F-í†µê³„ëŸ‰
    n1, n2 = len(y1), len(y2)
    k = X.shape[1]  # ë³€ìˆ˜ ê°œìˆ˜

    numerator = (rss_full - (rss1 + rss2)) / k
    denominator = (rss1 + rss2) / (n1 + n2 - 2*k)

    F_stat = numerator / denominator
    p_value = 1 - f.cdf(F_stat, k, n1 + n2 - 2*k)

    return {
        'F_stat': F_stat,
        'p_value': p_value,
        'coef_pre': model1.params[1],   # constant ì œì™¸
        'coef_post': model2.params[1],
        'coef_change': model2.params[1] - model1.params[1],
        'coef_change_pct': (model2.params[1] / model1.params[1] - 1) * 100
    }
```

#### Step 1.3: ë‹¤ì¤‘ ê²€ì • ë³´ì •

```python
from statsmodels.stats.multitest import multipletests

# Bonferroni ë³´ì • (ë³´ìˆ˜ì )
alpha = 0.05
n_tests = len(variables)
bonferroni_alpha = alpha / n_tests

# FDR ë³´ì • (Benjamini-Hochberg)
reject_fdr, pvals_corrected_fdr, _, _ = multipletests(
    p_values,
    alpha=alpha,
    method='fdr_bh'
)

# ê²°ê³¼
print(f"Bonferroni Î±: {bonferroni_alpha:.6f} (ìœ ì˜ ì‹œ ë§¤ìš° í™•ì‹¤)")
print(f"FDR ìœ ì˜ ë³€ìˆ˜: {reject_fdr.sum()} / {n_tests}")
```

### 4.4 í‘œì¤€ ì¶œë ¥

```python
# í‘œì¤€ DataFrame í˜•ì‹
chow_results = pd.DataFrame({
    'Variable': variables,
    'F_stat': f_stats,
    'p_value': p_values,
    'p_value_bonferroni': p_values_bonferroni,
    'p_value_fdr': p_values_fdr,
    'Significant_Bonferroni': reject_bonf,
    'Significant_FDR': reject_fdr,
    'Coef_Pre': coefs_pre,
    'Coef_Post': coefs_post,
    'Coef_Change': coef_changes,
    'Coef_Change_Pct': coef_change_pcts
})

# ì •ë ¬: F-í†µê³„ëŸ‰ ë‚´ë¦¼ì°¨ìˆœ
chow_results = chow_results.sort_values('F_stat', ascending=False)

# CSV ì €ì¥ (í‘œì¤€ ê²½ë¡œ)
chow_results.to_csv('results/chow_test_results.csv', index=False)
```

---

## 5. ê²€ì • 2: Quandt-Andrews Test

### 5.1 ëª©ì 

**"ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” ì§„ì§œ ë³€í™”ì ì€ ì–¸ì œì¸ê°€?"**

### 5.2 ê°€ì„¤

```
Hâ‚€: ëª¨ë“  Ï„ì—ì„œ êµ¬ì¡°ë³€í™” ì—†ìŒ
Hâ‚: ì–´ë–¤ Ï„ì—ì„œ êµ¬ì¡°ë³€í™” ìˆìŒ

Ï„: ê°€ëŠ¥í•œ ëª¨ë“  ë³€í™”ì  (15% ~ 85% êµ¬ê°„)
```

### 5.3 í‘œì¤€ í”„ë¡œì„¸ìŠ¤

#### Step 2.1: íƒìƒ‰ êµ¬ê°„ ì„¤ì •

```python
# í‘œì¤€ ì„¤ì •: 15% ~ 85% (Andrews 1993 ê¶Œì¥)
n = len(df)
start_idx = int(n * 0.15)
end_idx = int(n * 0.85)

print(f"íƒìƒ‰ êµ¬ê°„: {df.index[start_idx]} ~ {df.index[end_idx]}")
print(f"íƒìƒ‰ ë‚ ì§œ ìˆ˜: {end_idx - start_idx}ì¼")
```

#### Step 2.2: sup F-í†µê³„ëŸ‰ ê³„ì‚°

```python
def quandt_andrews_test_standardized(y, X, trim=0.15):
    """
    í‘œì¤€í™”ëœ Quandt-Andrews Test

    Parameters:
    -----------
    y : pd.Series (í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜)
    X : pd.DataFrame (í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜)
    trim : float (íƒìƒ‰ ì œì™¸ ë¹„ìœ¨, ì–‘ìª½)

    Returns:
    --------
    dict: sup F-í†µê³„ëŸ‰, ë³€í™”ì , ëª¨ë“  F-í†µê³„ëŸ‰
    """

    n = len(y)
    start = int(n * trim)
    end = int(n * (1 - trim))

    f_stats = []
    breakpoints = []

    # ëª¨ë“  ê°€ëŠ¥í•œ ë³€í™”ì ì—ì„œ Chow Test
    for tau in range(start, end):
        result = chow_test_standardized(y, X, tau)
        f_stats.append(result['F_stat'])
        breakpoints.append(y.index[tau])

    # sup F-í†µê³„ëŸ‰ (ìµœëŒ€ê°’)
    sup_f = max(f_stats)
    sup_f_idx = f_stats.index(sup_f)
    sup_f_date = breakpoints[sup_f_idx]

    return {
        'sup_F': sup_f,
        'breakpoint_date': sup_f_date,
        'breakpoint_idx': start + sup_f_idx,
        'all_F_stats': f_stats,
        'all_breakpoints': breakpoints
    }
```

#### Step 2.3: Critical Values (Andrews 1993)

```python
# Andrews (1993) Critical Values (trim=0.15)
ANDREWS_CRITICAL_VALUES = {
    0.10: 7.78,   # 10% ìœ ì˜ìˆ˜ì¤€
    0.05: 9.21,   # 5% ìœ ì˜ìˆ˜ì¤€
    0.01: 12.16   # 1% ìœ ì˜ìˆ˜ì¤€
}

def interpret_qa_test(sup_f, alpha=0.05):
    """sup F-í†µê³„ëŸ‰ í•´ì„"""
    critical_value = ANDREWS_CRITICAL_VALUES[alpha]

    if sup_f > critical_value:
        return f"ìœ ì˜ (sup F = {sup_f:.2f} > {critical_value})"
    else:
        return f"ë¹„ìœ ì˜ (sup F = {sup_f:.2f} â‰¤ {critical_value})"
```

### 5.4 í‘œì¤€ ì¶œë ¥

```python
# í‘œì¤€ DataFrame
qa_results = pd.DataFrame({
    'Variable': variables,
    'sup_F': sup_f_stats,
    'Breakpoint_Date': breakpoint_dates,
    'Significant_5pct': [f > 9.21 for f in sup_f_stats],
    'Significant_1pct': [f > 12.16 for f in sup_f_stats]
})

# ì •ë ¬
qa_results = qa_results.sort_values('sup_F', ascending=False)

# CSV ì €ì¥
qa_results.to_csv('results/quandt_andrews_results.csv', index=False)
```

---

## 6. ê²€ì • 3: CUSUM Test

### 6.1 ëª©ì 

**"êµ¬ì¡°ë³€í™”ê°€ ì ì§„ì ì¸ê°€, ê¸‰ê²©í•œê°€?"**

### 6.2 ê°€ì„¤

```
Hâ‚€: ì•ˆì •ì  (CUSUMì´ ê²½ê³„ ë‚´)
Hâ‚: ë¶ˆì•ˆì • (CUSUMì´ ê²½ê³„ ì´íƒˆ)

ê²½ê³„ ì´íƒˆ = ê¸‰ê²©í•œ ë³€í™” (1ì¼ ë§Œì— ë’¤ë°”ë€œ)
ê²½ê³„ ë‚´ = ì ì§„ì  ë³€í™” (ëª‡ ì£¼~ëª‡ ë‹¬)
```

### 6.3 í‘œì¤€ í”„ë¡œì„¸ìŠ¤

#### Step 3.1: CUSUM ê³„ì‚°

```python
def cusum_test_standardized(y, X):
    """
    í‘œì¤€í™”ëœ CUSUM Test

    Parameters:
    -----------
    y : pd.Series (í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜)
    X : pd.DataFrame (í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜)

    Returns:
    --------
    dict: CUSUM ê²½ë¡œ, ê²½ê³„ì„ , ì´íƒˆ ì—¬ë¶€
    """

    # 1. ì „ì²´ íšŒê·€ë¡œ ì”ì°¨ ê³„ì‚°
    model = sm.OLS(y, X).fit()
    residuals = model.resid

    # 2. í‘œì¤€í™”ëœ ì”ì°¨
    std_residuals = residuals / residuals.std()

    # 3. ëˆ„ì í•©
    cusum = std_residuals.cumsum()

    # 4. ê²½ê³„ì„  (Brown-Durbin-Evans, 1975)
    n = len(y)
    boundary = 0.948 * np.sqrt(n)  # 5% ìœ ì˜ìˆ˜ì¤€

    # 5. ê²½ê³„ ì´íƒˆ í™•ì¸
    breaches = (cusum.abs() > boundary).sum()

    return {
        'cusum': cusum,
        'boundary': boundary,
        'n_breaches': breaches,
        'max_cusum': cusum.abs().max(),
        'breach_ratio': cusum.abs().max() / boundary
    }
```

#### Step 3.2: í•´ì„ ê¸°ì¤€

```python
def interpret_cusum(result):
    """CUSUM ê²°ê³¼ í•´ì„"""

    breach_ratio = result['breach_ratio']

    if result['n_breaches'] > 0:
        return {
            'type': 'ABRUPT',
            'description': 'ê¸‰ê²©í•œ ë³€í™” (í•˜ë£¨ ë§Œì— ë’¤ë°”ë€œ)',
            'speed': 'VERY_FAST',
            'interpretation': 'ê²½ê³„ ì´íƒˆ ë°œìƒ â†’ ë‹¨ì ˆì  êµ¬ì¡°ë³€í™”'
        }
    elif breach_ratio > 0.8:
        return {
            'type': 'RAPID',
            'description': 'ë¹ ë¥¸ ì ì§„ì  ë³€í™” (1-2ì£¼)',
            'speed': 'FAST',
            'interpretation': 'ê²½ê³„ ê·¼ì ‘ â†’ ë¹ ë¥¸ ë³€í™”'
        }
    elif breach_ratio > 0.5:
        return {
            'type': 'MODERATE',
            'description': 'ì¤‘ê°„ ì†ë„ ì ì§„ì  ë³€í™” (1-2ê°œì›”)',
            'speed': 'MODERATE',
            'interpretation': 'ê²½ê³„ ë‚´ â†’ ì ì§„ì  ë³€í™”'
        }
    else:
        return {
            'type': 'GRADUAL',
            'description': 'ëŠë¦° ì ì§„ì  ë³€í™” (3-6ê°œì›”)',
            'speed': 'SLOW',
            'interpretation': 'ê²½ê³„ ë‚´ â†’ ë§¤ìš° ì ì§„ì  ë³€í™”'
        }
```

### 6.4 í‘œì¤€ ì¶œë ¥

```python
# í‘œì¤€ DataFrame
cusum_results = pd.DataFrame({
    'Variable': variables,
    'Max_CUSUM': max_cusums,
    'Boundary': boundaries,
    'Breach_Ratio': breach_ratios,
    'N_Breaches': n_breaches,
    'Change_Type': change_types,
    'Change_Speed': change_speeds
})

# CSV ì €ì¥
cusum_results.to_csv('results/cusum_test_results.csv', index=False)
```

---

## 7. ê²°ê³¼ í•´ì„ ê¸°ì¤€

### 7.1 3ë‹¨ê³„ í†µí•© ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chow Test ê²°ê³¼                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ p < 0.00042 (Bonferroni) â”€â”€â”€â”€â”€â”
         â”‚                                  â”‚
         â””â”€ p â‰¥ 0.00042 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Quandt-Andrews Test ê²°ê³¼             â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚                                 â”‚
         â”œâ”€ sup F > 9.21 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                                 â”‚
         â””â”€ sup F â‰¤ 9.21 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ CUSUM Test ê²°ê³¼                      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚                                 â”‚
         â”œâ”€ ê²½ê³„ ì´íƒˆ â”€â”€â”€â”€â”€â”€â–º ê¸‰ê²©í•œ ë³€í™”  â”‚
         â”‚                                 â”‚
         â””â”€ ê²½ê³„ ë‚´ â”€â”€â”€â”€â”€â”€â”€â”€â–º ì ì§„ì  ë³€í™”  â”‚
                                           â”‚
                                           â–¼
                                    ìµœì¢… ê²°ë¡ 
```

### 7.2 í‘œì¤€ í•´ì„í‘œ

| Chow | QA | CUSUM | ê²°ë¡  | ì‹ ë¢°ë„ |
|------|-------|-------|------|--------|
| âœ… ìœ ì˜ | âœ… ìœ ì˜ | ğŸ”´ ì´íƒˆ | **ê¸‰ê²©í•˜ê³  í™•ì‹¤í•œ êµ¬ì¡°ë³€í™”** | â˜…â˜…â˜…â˜…â˜… |
| âœ… ìœ ì˜ | âœ… ìœ ì˜ | âœ… ë‚´ | **ì ì§„ì ì´ì§€ë§Œ í™•ì‹¤í•œ êµ¬ì¡°ë³€í™”** | â˜…â˜…â˜…â˜…â˜† |
| âœ… ìœ ì˜ | âŒ ë¹„ìœ ì˜ | âœ… ë‚´ | **ETF ë‚ ì§œëŠ” ë§ì§€ë§Œ ì ì§„ì ** | â˜…â˜…â˜…â˜†â˜† |
| âŒ ë¹„ìœ ì˜ | âœ… ìœ ì˜ | âœ… ë‚´ | **ETF ë‚ ì§œê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë‚  ë³€í™”** | â˜…â˜…â˜…â˜†â˜† |
| âŒ ë¹„ìœ ì˜ | âŒ ë¹„ìœ ì˜ | âœ… ë‚´ | **êµ¬ì¡°ë³€í™” ì—†ìŒ** | â˜…â˜…â˜…â˜…â˜† |

### 7.3 ë³€í™”ì  ë‚ ì§œ ë¹„êµ

```python
def compare_breakpoints(chow_date, qa_date, tolerance_days=30):
    """
    Chowì™€ QAì˜ ë³€í™”ì  ë‚ ì§œ ë¹„êµ

    Parameters:
    -----------
    chow_date : datetime (ì§€ì •í•œ ë‚ ì§œ)
    qa_date : datetime (ë°ì´í„°ì—ì„œ ì°¾ì€ ë‚ ì§œ)
    tolerance_days : int (í—ˆìš© ì˜¤ì°¨, ì¼)

    Returns:
    --------
    str: í•´ì„
    """

    diff_days = abs((qa_date - chow_date).days)

    if diff_days == 0:
        return "ì™„ë²½íˆ ì¼ì¹˜ (ì§€ì • ë‚ ì§œ = ë°œê²¬ ë‚ ì§œ)"
    elif diff_days <= tolerance_days:
        return f"ê·¼ì ‘ ì¼ì¹˜ ({diff_days}ì¼ ì°¨ì´, í—ˆìš© ë²”ìœ„ ë‚´)"
    else:
        return f"ë¶ˆì¼ì¹˜ ({diff_days}ì¼ ì°¨ì´, ë‹¤ë¥¸ ì´ë²¤íŠ¸ ê°€ëŠ¥ì„±)"
```

---

## 8. í‘œì¤€ ë³´ê³  ì–‘ì‹

### 8.1 ìš”ì•½ í†µê³„

```python
# í‘œì¤€ ìš”ì•½ ë³´ê³ ì„œ
summary_report = f"""
================================================================================
êµ¬ì¡°ë³€í™” ê²€ì • í‘œì¤€ ë³´ê³ ì„œ
================================================================================

ã€ë°ì´í„° ì •ë³´ã€‘
  - ê¸°ê°„: {df.index[0]} ~ {df.index[-1]}
  - ìƒ˜í”Œ ìˆ˜: {len(df)}ì¼
  - ë³€ìˆ˜ ìˆ˜: {len(variables)}ê°œ
  - ë³€í™”ì  ë‚ ì§œ: {BREAKPOINT_DATE} (ETF ìŠ¹ì¸ì¼)

ã€Chow Test ê²°ê³¼ã€‘
  - ê²€ì • ë³€ìˆ˜ ìˆ˜: {len(variables)}
  - Bonferroni ìœ ì˜: {bonf_significant}ê°œ ({bonf_significant/len(variables)*100:.1f}%)
  - FDR ìœ ì˜: {fdr_significant}ê°œ ({fdr_significant/len(variables)*100:.1f}%)

  ìƒìœ„ 5ê°œ ë³€ìˆ˜:
{chow_top5_table}

ã€Quandt-Andrews Test ê²°ê³¼ã€‘
  - ê²€ì • ë³€ìˆ˜ ìˆ˜: {len(variables)}
  - 5% ìœ ì˜: {qa_significant_5pct}ê°œ
  - 1% ìœ ì˜: {qa_significant_1pct}ê°œ

  ìƒìœ„ 5ê°œ ë³€ìˆ˜:
{qa_top5_table}

ã€CUSUM Test ê²°ê³¼ã€‘
  - ê²½ê³„ ì´íƒˆ ë³€ìˆ˜: {cusum_breaches}ê°œ
  - ì ì§„ì  ë³€í™”: {cusum_gradual}ê°œ

  ë³€í™” ì†ë„ ë¶„í¬:
    - ê¸‰ê²©: {cusum_abrupt}ê°œ
    - ë¹ ë¦„: {cusum_rapid}ê°œ
    - ì¤‘ê°„: {cusum_moderate}ê°œ
    - ëŠë¦¼: {cusum_slow}ê°œ

ã€ì¢…í•© ê²°ë¡ ã€‘
{overall_conclusion}

================================================================================
"""

# ì €ì¥
with open('results/structural_change_summary.txt', 'w', encoding='utf-8') as f:
    f.write(summary_report)
```

### 8.2 ì‹œê°í™” í‘œì¤€

```python
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

def plot_standard_results(chow_results, qa_results, cusum_results):
    """í‘œì¤€ ì‹œê°í™”"""

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. Chow Test: F-í†µê³„ëŸ‰ ìƒìœ„ 30ê°œ
    top30_chow = chow_results.nlargest(30, 'F_stat')
    axes[0, 0].barh(top30_chow['Variable'], top30_chow['F_stat'])
    axes[0, 0].set_xlabel('F-í†µê³„ëŸ‰')
    axes[0, 0].set_title('Chow Test: F-í†µê³„ëŸ‰ TOP 30')
    axes[0, 0].axvline(x=10, color='r', linestyle='--', label='ì¼ë°˜ì  ìœ ì˜ ê¸°ì¤€')

    # 2. QA Test: sup F-í†µê³„ëŸ‰ ìƒìœ„ 30ê°œ
    top30_qa = qa_results.nlargest(30, 'sup_F')
    axes[0, 1].barh(top30_qa['Variable'], top30_qa['sup_F'])
    axes[0, 1].set_xlabel('sup F-í†µê³„ëŸ‰')
    axes[0, 1].set_title('Quandt-Andrews: sup F TOP 30')
    axes[0, 1].axvline(x=9.21, color='r', linestyle='--', label='5% CV')

    # 3. ë³€í™”ì  ë‚ ì§œ ë¶„í¬
    qa_dates = pd.to_datetime(qa_results['Breakpoint_Date'])
    axes[1, 0].hist(qa_dates, bins=50, edgecolor='black')
    axes[1, 0].axvline(x=pd.to_datetime(BREAKPOINT_DATE),
                       color='r', linestyle='--', linewidth=2,
                       label='ETF ìŠ¹ì¸ì¼')
    axes[1, 0].set_xlabel('ë³€í™”ì  ë‚ ì§œ')
    axes[1, 0].set_ylabel('ë³€ìˆ˜ ê°œìˆ˜')
    axes[1, 0].set_title('Quandt-Andrews: ë³€í™”ì  ë‚ ì§œ ë¶„í¬')
    axes[1, 0].legend()

    # 4. CUSUM: ë³€í™” ìœ í˜• ë¶„í¬
    change_type_counts = cusum_results['Change_Type'].value_counts()
    axes[1, 1].pie(change_type_counts, labels=change_type_counts.index,
                   autopct='%1.1f%%')
    axes[1, 1].set_title('CUSUM: ë³€í™” ìœ í˜• ë¶„í¬')

    plt.tight_layout()
    plt.savefig('results/structural_change_tests_summary.png', dpi=300, bbox_inches='tight')
    plt.close()
```

---

## 9. ì²´í¬ë¦¬ìŠ¤íŠ¸

### 9.1 ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ë°ì´í„° í™•ì¸**
  - [ ] ê²°ì¸¡ì¹˜ 0ê°œ í™•ì¸
  - [ ] ì´ìƒì¹˜ ì²˜ë¦¬ ì™„ë£Œ (Winsorization)
  - [ ] ë³€ìˆ˜ í‘œì¤€í™” ì™„ë£Œ (Z-score)
  - [ ] ì‹œê³„ì—´ ìˆœì„œ í™•ì¸ (ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬)

- [ ] **íŒŒë¼ë¯¸í„° ì„¤ì •**
  - [ ] ë³€í™”ì  ë‚ ì§œ ì§€ì • (BREAKPOINT_DATE)
  - [ ] QA íƒìƒ‰ êµ¬ê°„ ì„¤ì • (trim=0.15)
  - [ ] ë‹¤ì¤‘ ê²€ì • ë³´ì • ë°©ë²• ì„ íƒ (Bonferroni/FDR)
  - [ ] HAC lag ì„¤ì • (maxlags=5 ê¶Œì¥)

- [ ] **í™˜ê²½ ì„¤ì •**
  - [ ] Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ (statsmodels, scipy, pandas)
  - [ ] ê²°ê³¼ ì €ì¥ í´ë” ìƒì„± (results/)
  - [ ] í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)

### 9.2 ì‹¤í–‰ ì¤‘ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **Chow Test**
  - [ ] ëª¨ë“  ë³€ìˆ˜ì— ëŒ€í•´ ê²€ì • ì™„ë£Œ
  - [ ] F-í†µê³„ëŸ‰, p-value ê³„ì‚°
  - [ ] Bonferroni, FDR ë³´ì • ì ìš©
  - [ ] ê³„ìˆ˜ ë³€í™”ìœ¨ ê³„ì‚°

- [ ] **Quandt-Andrews Test**
  - [ ] íƒìƒ‰ êµ¬ê°„ ë‚´ ëª¨ë“  ë³€í™”ì  ê²€ì •
  - [ ] sup F-í†µê³„ëŸ‰ ê³„ì‚°
  - [ ] ë³€í™”ì  ë‚ ì§œ ê¸°ë¡
  - [ ] Critical value ë¹„êµ

- [ ] **CUSUM Test**
  - [ ] CUSUM ê²½ë¡œ ê³„ì‚°
  - [ ] ê²½ê³„ì„  ê³„ì‚°
  - [ ] ê²½ê³„ ì´íƒˆ ì—¬ë¶€ í™•ì¸
  - [ ] ë³€í™” ì†ë„ ë¶„ë¥˜

### 9.3 ì‹¤í–‰ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ê²°ê³¼ ê²€ì¦**
  - [ ] 3ê°€ì§€ ê²€ì • ê²°ê³¼ ì¼ê´€ì„± í™•ì¸
  - [ ] ë³€í™”ì  ë‚ ì§œ ë¹„êµ (Chow vs QA)
  - [ ] ì´ìƒ ê²°ê³¼ ì¬í™•ì¸ (F-stat > 10,000 ë“±)

- [ ] **ê²°ê³¼ ì €ì¥**
  - [ ] CSV íŒŒì¼ ì €ì¥ (chow, qa, cusum)
  - [ ] ìš”ì•½ ë³´ê³ ì„œ ì €ì¥ (TXT)
  - [ ] ì‹œê°í™” ì €ì¥ (PNG)

- [ ] **ë¬¸ì„œí™”**
  - [ ] ê²€ì • ì¡°ê±´ ê¸°ë¡
  - [ ] ì£¼ìš” ë°œê²¬ì‚¬í•­ ì •ë¦¬
  - [ ] í•œê³„ì  ë° ì£¼ì˜ì‚¬í•­ ê¸°ë¡

---

## 10. Python êµ¬í˜„ ì˜ˆì‹œ (ì „ì²´ íŒŒì´í”„ë¼ì¸)

```python
import pandas as pd
import numpy as np
import statsmodels.api as sm
from scipy import stats
from statsmodels.stats.multitest import multipletests
import matplotlib.pyplot as plt

class StructuralChangeTestingFramework:
    """êµ¬ì¡°ë³€í™” ê²€ì • í‘œì¤€ í”„ë ˆì„ì›Œí¬"""

    def __init__(self, df, y_col, breakpoint_date, trim=0.15):
        """
        Parameters:
        -----------
        df : pd.DataFrame (í‘œì¤€í™”ëœ ë°ì´í„°)
        y_col : str (ì¢…ì†ë³€ìˆ˜ ì»¬ëŸ¼ëª…)
        breakpoint_date : str (ë³€í™”ì  ë‚ ì§œ, 'YYYY-MM-DD')
        trim : float (QA íƒìƒ‰ êµ¬ê°„ ì œì™¸ ë¹„ìœ¨)
        """
        self.df = df
        self.y_col = y_col
        self.breakpoint_date = pd.to_datetime(breakpoint_date)
        self.trim = trim

        # ë³€í™”ì  ì¸ë±ìŠ¤
        self.breakpoint_idx = self.df.index.get_loc(self.breakpoint_date)

        # ê²°ê³¼ ì €ì¥
        self.chow_results = None
        self.qa_results = None
        self.cusum_results = None

    def run_all_tests(self, variables):
        """ì „ì²´ ê²€ì • ì‹¤í–‰"""

        print("=" * 80)
        print("êµ¬ì¡°ë³€í™” ê²€ì • ì‹œì‘")
        print("=" * 80)

        # Step 1: Chow Test
        print("\n[1/3] Chow Test ì‹¤í–‰ ì¤‘...")
        self.chow_results = self._run_chow_test(variables)
        print(f"ì™„ë£Œ: {len(self.chow_results)}ê°œ ë³€ìˆ˜ ê²€ì •")

        # Step 2: Quandt-Andrews Test
        print("\n[2/3] Quandt-Andrews Test ì‹¤í–‰ ì¤‘...")
        self.qa_results = self._run_qa_test(variables)
        print(f"ì™„ë£Œ: {len(self.qa_results)}ê°œ ë³€ìˆ˜ ê²€ì •")

        # Step 3: CUSUM Test
        print("\n[3/3] CUSUM Test ì‹¤í–‰ ì¤‘...")
        self.cusum_results = self._run_cusum_test(variables)
        print(f"ì™„ë£Œ: {len(self.cusum_results)}ê°œ ë³€ìˆ˜ ê²€ì •")

        print("\n" + "=" * 80)
        print("ëª¨ë“  ê²€ì • ì™„ë£Œ!")
        print("=" * 80)

        return self.chow_results, self.qa_results, self.cusum_results

    def _run_chow_test(self, variables):
        """Chow Test ì‹¤í–‰"""
        results = []

        for var in variables:
            y = self.df[self.y_col]
            X = sm.add_constant(self.df[[var]])

            result = self._chow_test_single(y, X, self.breakpoint_idx)
            result['Variable'] = var
            results.append(result)

        df_results = pd.DataFrame(results)

        # ë‹¤ì¤‘ ê²€ì • ë³´ì •
        reject_bonf, pvals_bonf, _, _ = multipletests(
            df_results['p_value'], alpha=0.05, method='bonferroni'
        )
        reject_fdr, pvals_fdr, _, _ = multipletests(
            df_results['p_value'], alpha=0.05, method='fdr_bh'
        )

        df_results['Significant_Bonferroni'] = reject_bonf
        df_results['Significant_FDR'] = reject_fdr
        df_results['p_value_Bonferroni'] = pvals_bonf
        df_results['p_value_FDR'] = pvals_fdr

        return df_results.sort_values('F_stat', ascending=False)

    def _chow_test_single(self, y, X, breakpoint_idx):
        """ë‹¨ì¼ ë³€ìˆ˜ Chow Test"""
        # (ì´ì „ ì½”ë“œ ì°¸ì¡°)
        pass

    def _run_qa_test(self, variables):
        """Quandt-Andrews Test ì‹¤í–‰"""
        # (ì´ì „ ì½”ë“œ ì°¸ì¡°)
        pass

    def _run_cusum_test(self, variables):
        """CUSUM Test ì‹¤í–‰"""
        # (ì´ì „ ì½”ë“œ ì°¸ì¡°)
        pass

    def save_results(self, output_dir='results'):
        """ê²°ê³¼ ì €ì¥"""
        import os
        os.makedirs(output_dir, exist_ok=True)

        self.chow_results.to_csv(f'{output_dir}/chow_test_results.csv', index=False)
        self.qa_results.to_csv(f'{output_dir}/quandt_andrews_results.csv', index=False)
        self.cusum_results.to_csv(f'{output_dir}/cusum_test_results.csv', index=False)

        print(f"\nê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}/")

    def plot_results(self):
        """í‘œì¤€ ì‹œê°í™”"""
        # (ì´ì „ ì½”ë“œ ì°¸ì¡°)
        pass

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # 1. ë°ì´í„° ë¡œë“œ ë° í‘œì¤€í™”
    df = pd.read_csv('integrated_data_full_v2.csv', index_col='Date', parse_dates=True)
    df_scaled = standardize_data(df)  # í‘œì¤€í™” í•¨ìˆ˜

    # 2. í”„ë ˆì„ì›Œí¬ ì´ˆê¸°í™”
    framework = StructuralChangeTestingFramework(
        df=df_scaled,
        y_col='Close',
        breakpoint_date='2024-01-10',
        trim=0.15
    )

    # 3. ê²€ì • ì‹¤í–‰
    variables = [col for col in df_scaled.columns if col != 'Close']
    chow, qa, cusum = framework.run_all_tests(variables)

    # 4. ê²°ê³¼ ì €ì¥
    framework.save_results()

    # 5. ì‹œê°í™”
    framework.plot_results()
```

---

## 11. í•œê³„ì  ë° ì£¼ì˜ì‚¬í•­

### 11.1 í‘œì¤€í™”ì˜ í•œê³„

âš ï¸ **í‘œì¤€í™” í›„ì—ë„ ì£¼ì˜í•  ì **:
- ë¹„ì„ í˜• ê´€ê³„ëŠ” í¬ì°©í•˜ì§€ ëª»í•¨
- ì‹œì°¨ íš¨ê³¼ (lagged effect) ë¯¸ë°˜ì˜
- ë‹¤ë³€ëŸ‰ ìƒí˜¸ì‘ìš© ë¬´ì‹œ (ë‹¨ë³€ëŸ‰ ê²€ì •ì´ë¯€ë¡œ)

### 11.2 ë‹¤ì¤‘ ê²€ì •ì˜ ë”œë ˆë§ˆ

âš ï¸ **Bonferroni vs FDR**:
- Bonferroni: ë„ˆë¬´ ë³´ìˆ˜ì  (Type II ì˜¤ë¥˜ ì¦ê°€)
- FDR: ê±°ì§“ ë°œê²¬ ê°€ëŠ¥ì„± (Type I ì˜¤ë¥˜)
- **ê¶Œì¥**: ë‘˜ ë‹¤ ë³´ê³ , FDR ìš°ì„  í•´ì„

### 11.3 ë³€í™”ì  ë‚ ì§œì˜ ë¶ˆí™•ì‹¤ì„±

âš ï¸ **QA Test ë³€í™”ì  í•´ì„**:
- ë°ì´í„° ê¸°ë°˜ ë³€í™”ì  â‰  ì§„ì§œ ì¸ê³¼ ë‚ ì§œ
- ETF ìŠ¹ì¸ì¼ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (ì •ìƒ)
- ì—¬ëŸ¬ ë³€ìˆ˜ì˜ ë³€í™”ì  ë¶„í¬ë¥¼ ë´ì•¼ í•¨

### 11.4 CUSUMì˜ ë¯¼ê°ë„

âš ï¸ **ê²½ê³„ ì´íƒˆ í•´ì„**:
- ê²½ê³„ ì´íƒˆ = ê¸‰ê²©í•œ ë³€í™”ì´ì§€ë§Œ
- ê²½ê³„ ë‚´ â‰  ë³€í™” ì—†ìŒ!
- ì ì§„ì ì´ì§€ë§Œ í° ë³€í™”ë„ ê°€ëŠ¥

---

## 12. ì°¸ê³ ë¬¸í—Œ

1. **Chow, G. C. (1960)**. "Tests of Equality Between Sets of Coefficients in Two Linear Regressions". *Econometrica*, 28(3), 591-605.

2. **Andrews, D. W. K. (1993)**. "Tests for Parameter Instability and Structural Change with Unknown Change Point". *Econometrica*, 61(4), 821-856.

3. **Brown, R. L., Durbin, J., & Evans, J. M. (1975)**. "Techniques for Testing the Constancy of Regression Relationships over Time". *Journal of the Royal Statistical Society: Series B*, 37(2), 149-163.

4. **Newey, W. K., & West, K. D. (1987)**. "A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix". *Econometrica*, 55(3), 703-708.

5. **Benjamini, Y., & Hochberg, Y. (1995)**. "Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing". *Journal of the Royal Statistical Society: Series B*, 57(1), 289-300.

---

**ì‘ì„±ì¼**: 2025-11-09
**ë²„ì „**: 1.0
**ë¼ì´ì„ ìŠ¤**: MIT

Â© 2025 Bitcoin ETF Structural Change Analysis Project
